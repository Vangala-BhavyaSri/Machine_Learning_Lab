{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cfa0bc5-3a4b-431e-ad37-b01c7c008d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d342a5a-fbf1-47d0-9c0b-1bad891d7868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1657, 3)\n",
      "Test: (1102, 3)\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "import pandas as pd\n",
    "df_train=pd.read_csv(\"newsgroups_train.csv\")\n",
    "df_test=pd.read_csv(\"newsgroups_test.csv\")\n",
    "print(\"Train:\",df_train.shape)\n",
    "print(\"Test:\",df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b27b05-4b43-4149-8454-9ae3bd9f3956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3&4\n",
    "#Done in above\n",
    "#2 Question\n",
    "#new_train=fetch_20newsgroup(subset='train',categories=cats)\n",
    "#new_test=fetch_20newsgroup(subset='test',categories=cats)\n",
    "#if they dont give the dataset dircetly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98897dc-4430-452b-bf22-3e4f6c28c4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Labels: ['sci.space' 'comp.graphics' 'alt.atheism']\n"
     ]
    }
   ],
   "source": [
    "# 5. Print all target labels\n",
    "\n",
    "print(\"Target Labels:\",df_train['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e962d1-47b9-4a6c-86a8-5144b43ef115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "#already done in 5th Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4402b92e-625f-4547-b659-e140c96acb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Categories: ['alt.atheism', 'comp.graphics', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "selected_categories=['alt.atheism','comp.graphics','sci.space']\n",
    "print(\"Selected Categories:\",selected_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef363b5f-5be6-4cfa-a9d6-f5a4415e9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 to 8 th done in above\n",
    "\n",
    "#except 3 catgories->filter\n",
    "#df_test_filter=df_test[df_test['category'].isin(selected_categories)]\n",
    "#print(df_test_filter.shape)\n",
    "#print(df_test_filter.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "496ee2ab-beee-41dd-8284-8479ce7b7361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New_Training Set: [2 1 0]\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "print(\"New_Training Set:\",df_train['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48382a03-1556-4204-a09f-bd2b0c697058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th training article: From: henry@zoo.toronto.edu (Henry Spencer)\n",
      "Subject: Re: TRUE \"GLOBE\", Who makes it?\n",
      "Organization: U of Toronto Zoology\n",
      "Lines: 12\n",
      "\n",
      "In article <bill.047m@xpresso.UUCP> bill@xpresso.UUCP (Bill Vance) writes:\n",
      ">It has been known for quite a while that the earth is actually more pear\n",
      ">shaped than globular/spherical.  Does anyone make a \"globe\" that is accurate\n",
      ">as to actual shape, landmass configuration/Long/Lat lines etc.?\n",
      "\n",
      "I don't think you're going to be able to see the differences from a sphere\n",
      "unless they are greatly exaggerated.  Even the equatorial bulge is only\n",
      "about 1 part in 300 -- you'd never notice a 1mm error in a 30cm globe --\n",
      "and the other deviations from spherical shape are much smaller.\n",
      "-- \n",
      "SVR4 resembles a high-speed collision   | Henry Spencer @ U of Toronto Zoology\n",
      "between SVR3 and SunOS.    - Dick Dunn  |  henry@zoo.toronto.edu  utzoo!henry\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "print(\"5th training article:\",df_train.iloc[4]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f6a675-b04a-4434-bc08-aad29e859720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (1657, 3) Test Data Shape: (1102, 3)\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "print(\"Train Data Shape:\",df_train.shape,\"Test Data Shape:\",df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40e7e131-dc7b-43ae-9b95-793af7aa60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "#not applicable for csv files\n",
    "#if its not csv\n",
    "#selected_categories=['alt.atheism','comp.graphics','sci.space']\n",
    "#newsgroup_train=fetch_20newsgroups(subset='train',categories=selected_categories)\n",
    "#newsgroup_test=fetch_20newsgroups(subset='test',categories=selected_categories)\n",
    "#print(\"training data size:\",newsgroup_train.data)\n",
    "#print(\"testing data size:\",newsgroup_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56aa1f5d-5d36-4f37-9bf2-d5433d57d0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12719)\t1\n",
      "  (0, 9599)\t1\n",
      "  (0, 19118)\t2\n",
      "  (0, 8021)\t1\n",
      "  (0, 1435)\t1\n",
      "  (0, 25770)\t1\n",
      "  (0, 22452)\t1\n",
      "  (0, 28288)\t3\n",
      "  (0, 16593)\t1\n",
      "  (0, 12496)\t4\n",
      "  (0, 8345)\t3\n",
      "  (0, 19968)\t1\n",
      "  (0, 19826)\t1\n",
      "  (0, 8112)\t1\n",
      "  (0, 24252)\t1\n",
      "  (0, 2173)\t1\n",
      "  (0, 1619)\t1\n",
      "  (0, 3416)\t1\n",
      "  (0, 17184)\t1\n",
      "  (0, 13608)\t1\n",
      "  (0, 17048)\t1\n",
      "  (0, 10463)\t1\n",
      "  (0, 26689)\t1\n",
      "  (0, 5013)\t1\n",
      "  (0, 13316)\t1\n",
      "  :\t:\n",
      "  (1656, 18609)\t1\n",
      "  (1656, 12805)\t2\n",
      "  (1656, 17462)\t8\n",
      "  (1656, 9202)\t1\n",
      "  (1656, 15868)\t2\n",
      "  (1656, 23624)\t2\n",
      "  (1656, 16075)\t3\n",
      "  (1656, 29142)\t2\n",
      "  (1656, 28068)\t1\n",
      "  (1656, 8277)\t1\n",
      "  (1656, 3501)\t1\n",
      "  (1656, 19121)\t1\n",
      "  (1656, 27936)\t1\n",
      "  (1656, 13519)\t1\n",
      "  (1656, 2827)\t1\n",
      "  (1656, 18533)\t1\n",
      "  (1656, 19653)\t1\n",
      "  (1656, 15418)\t1\n",
      "  (1656, 27085)\t1\n",
      "  (1656, 2717)\t1\n",
      "  (1656, 27169)\t1\n",
      "  (1656, 1122)\t1\n",
      "  (1656, 9138)\t1\n",
      "  (1656, 13349)\t1\n",
      "  (1656, 3630)\t1\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "vectorizer=CountVectorizer()\n",
    "X_train_counts=vectorizer.fit_transform(df_train['text'])\n",
    "y_train_counts=vectorizer.transform(df_train['text'])\n",
    "print(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7812c0ce-af2d-4fb3-8de3-491f7daecb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14\n",
    "br=BernoulliNB()\n",
    "br.fit(X_train_counts,df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f03ed1ce-86b0-49e4-8d9d-a0327c00348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1657, 29663) (1102, 29663)\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "vectorizer=CountVectorizer()\n",
    "X_train_counts=vectorizer.fit_transform(df_train['text'])\n",
    "y_test_counts=vectorizer.transform(df_test['text'])\n",
    "print(X_train_counts.shape,X_test_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff67dab0-d9d5-47fe-ae2c-b0034e049134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "prediction=br.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fac1e459-c49d-4187-9bd0-61872e3c03db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Accuracy_score: 0.852994555353902\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "accuracy=accuracy_score(df_test['target'],prediction)\n",
    "print(\"Bernoulli Accuracy_score:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99e13248-531a-465c-9f53-f2ac6cd33562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_tfidf: 0.9473684210526315\n",
      "confusion matrics:\n",
      " [[303   2  14]\n",
      " [  6 357  26]\n",
      " [  2   8 384]]\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       319\n",
      "           1       0.97      0.92      0.94       389\n",
      "           2       0.91      0.97      0.94       394\n",
      "\n",
      "    accuracy                           0.95      1102\n",
      "   macro avg       0.95      0.95      0.95      1102\n",
      "weighted avg       0.95      0.95      0.95      1102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "tfidf_vectorizer=TfidfVectorizer()\n",
    "X_train_tfidf=tfidf_vectorizer.fit_transform(df_train['text'])\n",
    "y_test_tfidf=tfidf_vectorizer.transform(df_test['text'])\n",
    "\n",
    "mlb=MultinomialNB()\n",
    "mlb.fit(X_train_tfidf,df_train['target'])\n",
    "prediction_tfidf=mlb.predict(X_test_tfidf)\n",
    "accuracy_tfidf=accuracy_score(df_test['target'],prediction_tfidf)\n",
    "print(\"accuracy_tfidf:\",accuracy_tfidf)\n",
    "print(\"confusion matrics:\\n\",confusion_matrix(df_test['target'],prediction_tfidf))\n",
    "print(\"classification report:\\n\",classification_report(df_test['target'],prediction_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3ada410-9b65-48e3-8d4b-ccf80711d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "#done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c86a7852-9c79-414e-965c-04d7ce1e79e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3, 1657]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m X_test_counts_stop\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mtransform(df_test)\n\u001b[1;32m      6\u001b[0m br_stop\u001b[38;5;241m=\u001b[39mBernoulliNB()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mbr_stop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_counts_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m prediction_stop\u001b[38;5;241m=\u001b[39mbr_stop\u001b[38;5;241m.\u001b[39mpredict(X_test_counts_stop)\n\u001b[1;32m      9\u001b[0m accuracy_stop\u001b[38;5;241m=\u001b[39maccuracy_score(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m],prediction_stop)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/naive_bayes.py:745\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    748\u001b[0m     labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/naive_bayes.py:1197\u001b[0m, in \u001b[0;36mBernoulliNB._check_X_y\u001b[0;34m(self, X, y, reset)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 1197\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinarize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1199\u001b[0m         X \u001b[38;5;241m=\u001b[39m binarize(X, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinarize)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/naive_bayes.py:578\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X_y\u001b[0;34m(self, X, y, reset)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    577\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1164\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3, 1657]"
     ]
    }
   ],
   "source": [
    "#20\n",
    "vectorizer=CountVectorizer(stop_words='english',binary=True)\n",
    "X_train_counts_stop=vectorizer.fit_transform(df_train)\n",
    "X_test_counts_stop=vectorizer.transform(df_test)\n",
    "\n",
    "br_stop=BernoulliNB()\n",
    "br_stop.fit(X_train_counts_stop,df_train['target'])\n",
    "prediction_stop=br_stop.predict(X_test_counts_stop)\n",
    "accuracy_stop=accuracy_score(df_test['target'],prediction_stop)\n",
    "print(\"accuracy_stop:\",accuracy_stop)\n",
    "print(\"confusion matrics:\\n\",confusion_matrix(df_test['target'],prediction_stop))\n",
    "print(\"classification report:\\n\",classification_report(df_test['target'],prediction_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d915ea-1117-49a1-85cf-c4e262ab48f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
